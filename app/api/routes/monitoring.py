# Generated by Copilot
from fastapi import APIRouter
import psutil
import platform
import os
import shutil
import torch
from datetime import datetime
from typing import Dict, Any, List, Optional
from pydantic import BaseModel, Field

router = APIRouter()


class SystemInfo(BaseModel):
    system: str
    node_name: str
    release: str
    version: str
    machine: str
    processor: str
    uptime: str


class CpuInfo(BaseModel):
    physical_cores: int
    total_cores: int
    max_frequency: str
    current_frequency: str
    usage_per_core: List[str]
    total_usage: str
    temperatures: Optional[Dict[str, float]] = Field(
        description="CPU temperatures in Celsius"
    )


class MemoryInfo(BaseModel):
    total: str
    available: str
    used: str
    percentage: str


class GpuInfo(BaseModel):
    gpu_count: int
    current_device: int
    device_name: str
    memory_allocated: str
    memory_reserved: str


class DatasetInfo(BaseModel):
    images: int
    masks: int


class DataDirectoryInfo(BaseModel):
    path: str
    total_size: str
    max_size: str
    dataset: DatasetInfo


class StorageInfo(BaseModel):
    data_directory: DataDirectoryInfo


class DiskInfo(BaseModel):
    total: str
    used: str
    free: str
    percentage: str


class SystemMetrics(BaseModel):
    timestamp: str
    cpu: CpuInfo
    memory: MemoryInfo
    gpu: Optional[GpuInfo]


class SystemResponse(BaseModel):
    timestamp: str
    system: SystemInfo
    storage: StorageInfo
    disk: DiskInfo


class ModelInfo(BaseModel):
    size: str
    files: List[str]


class DirectoryStats(BaseModel):
    count: int
    size: str


class DatasetBreakdown(BaseModel):
    total_size: str
    images: DirectoryStats
    masks: DirectoryStats


class DataUsageBreakdown(BaseModel):
    dataset: DatasetBreakdown
    models: ModelInfo


class DataUsageResponse(BaseModel):
    total_usage: str
    max_size: str
    percentage_used: str
    breakdown: DataUsageBreakdown


def get_size(bytes: float, suffix: str = "B") -> str:
    """Convert bytes to human readable format"""
    factor = 1024
    for unit in ["", "K", "M", "G", "T", "P"]:
        if bytes < factor:
            return f"{bytes:.2f} {unit}{suffix}"
        bytes /= factor
    # Generated by Copilot
    return f"{bytes:.2f} P{suffix}"


@router.get("/system", response_model=SystemResponse)
def get_system_info() -> SystemResponse:
    """Get static system information"""
    # System Information
    uname = platform.uname()
    system_info = {
        "system": uname.system,
        "node_name": uname.node,
        "release": uname.release,
        "version": uname.version,
        "machine": uname.machine,
        "processor": uname.processor,
        "uptime": datetime.fromtimestamp(psutil.boot_time()).strftime(
            "%Y-%m-%d %H:%M:%S"
        ),
    }

    # Storage Information
    storage_info = StorageInfo(
        data_directory=DataDirectoryInfo(
            path="data/",
            total_size=get_size(
                sum(
                    os.path.getsize(os.path.join(dirpath, filename))
                    for dirpath, dirnames, filenames in os.walk("data/")
                    for filename in filenames
                )
            ),
            max_size="5GB",
            dataset=DatasetInfo(
                images=len(os.listdir("data/dataset/images")),
                masks=len(os.listdir("data/dataset/masks")),
            ),
        )
    )

    # Disk Information
    disk = psutil.disk_usage("/")
    disk_info = {
        "total": get_size(disk.total),
        "used": get_size(disk.used),
        "free": get_size(disk.free),
        "percentage": f"{disk.percent}%",
    }

    # Generated by Copilot
    return SystemResponse(
        timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        system=SystemInfo(**system_info),
        storage=storage_info,
        disk=DiskInfo(**disk_info),
    )


@router.get("/data-usage", response_model=DataUsageResponse)
def get_data_usage() -> DataUsageResponse:
    """Get detailed information about data directory usage"""
    data_path = "data/"
    dataset_path = os.path.join(data_path, "dataset")
    images_path = os.path.join(dataset_path, "images")
    masks_path = os.path.join(dataset_path, "masks")
    models_path = os.path.join(data_path, "models")

    # Create directories if they don't exist
    for path in [data_path, dataset_path, images_path, masks_path, models_path]:
        os.makedirs(path, exist_ok=True)

    def get_dir_size(path):
        total = 0
        with os.scandir(path) as it:
            for entry in it:
                if entry.is_file():
                    total += entry.stat().st_size
                elif entry.is_dir():
                    total += get_dir_size(entry.path)
        return total

    dataset_path = os.path.join(data_path, "dataset")
    images_path = os.path.join(dataset_path, "images")
    masks_path = os.path.join(dataset_path, "masks")
    models_path = os.path.join(data_path, "models")

    total_size = get_dir_size(data_path)
    return DataUsageResponse(
        total_usage=get_size(total_size),
        max_size="5GB",
        percentage_used=f"{(total_size / (5 * 1024 * 1024 * 1024)) * 100:.2f}%",
        breakdown=DataUsageBreakdown(
            dataset=DatasetBreakdown(
                total_size=get_size(get_dir_size(dataset_path)),
                images=DirectoryStats(
                    count=len(
                        [
                            f
                            for f in os.listdir(images_path)
                            if os.path.isfile(os.path.join(images_path, f))
                        ]
                    ),
                    size=get_size(get_dir_size(images_path)),
                ),
                masks=DirectoryStats(
                    count=len(
                        [
                            f
                            for f in os.listdir(masks_path)
                            if os.path.isdir(os.path.join(masks_path, f))
                        ]
                    ),
                    size=get_size(get_dir_size(masks_path)),
                ),
            ),
            models=ModelInfo(
                size=get_size(get_dir_size(models_path)),
                files=[
                    f
                    for f in os.listdir(models_path)
                    if os.path.isfile(os.path.join(models_path, f))
                ],
            ),
        ),
    )


@router.get("/metrics", response_model=SystemMetrics)
def get_system_metrics() -> SystemMetrics:
    """Get real-time system metrics (CPU, Memory, GPU)"""

    # CPU Information
    cpu_freq = psutil.cpu_freq()
    temperatures = {}
    try:
        temps = psutil.sensors_temperatures()
        if temps:
            cpu_temps = temps.get("coretemp", []) or temps.get(
                "k10temp", []
            )  # Intel or AMD
            if cpu_temps:
                for idx, temp in enumerate(cpu_temps):
                    temperatures[f"core_{idx}"] = temp.current
    except (AttributeError, KeyError):
        pass

    cpu_info = {
        "physical_cores": psutil.cpu_count(logical=False),
        "total_cores": psutil.cpu_count(logical=True),
        "max_frequency": f"{cpu_freq.max:.2f}Mhz",
        "current_frequency": f"{cpu_freq.current:.2f}Mhz",
        "usage_per_core": [
            f"{percentage:.1f}%"
            for percentage in psutil.cpu_percent(percpu=True, interval=0.1)
        ],
        "total_usage": f"{psutil.cpu_percent(interval=0.1)}%",
        "temperatures": temperatures if temperatures else None,
    }

    # Memory Information
    svmem = psutil.virtual_memory()
    memory_info = {
        "total": get_size(svmem.total),
        "available": get_size(svmem.available),
        "used": get_size(svmem.used),
        "percentage": f"{svmem.percent}%",
    }

    # GPU Information (if CUDA is available)
    gpu_info = {}
    if torch.cuda.is_available():
        gpu_info = {
            "gpu_count": torch.cuda.device_count(),
            "current_device": torch.cuda.current_device(),
            "device_name": torch.cuda.get_device_name(0),
            "memory_allocated": get_size(torch.cuda.memory_allocated(0)),
            "memory_reserved": get_size(torch.cuda.memory_reserved(0)),
        }

    return SystemMetrics(
        timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        cpu=CpuInfo(**cpu_info),
        memory=MemoryInfo(**memory_info),
        gpu=GpuInfo(**gpu_info) if gpu_info else None,
    )
