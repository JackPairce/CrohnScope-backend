{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c523e952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated by Copilot\n",
    "# Core imports\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import random\n",
    "import logging\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path(os.getcwd()).parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "\n",
    "from app.db.models import Image,Mask\n",
    "from app.db.session import SessionLocal\n",
    "# PyTorch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "\n",
    "# Import project modules\n",
    "from app.services.ai.Unet import training\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seeds\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed) if torch.cuda.is_available() else None\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Set paths\n",
    "data_path = Path(project_root, \"data\")\n",
    "image_path = data_path / \"dataset\" / \"images\"\n",
    "mask_path = data_path / \"dataset\" / \"masks\"\n",
    "model_path = data_path / \"models\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2286dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training on all images\n",
    "from app.db.models import Patch\n",
    "from app.services.image.patch_service import save_image_as_patches\n",
    "\n",
    "\n",
    "def get_data_from_db():\n",
    "    \"\"\"\n",
    "    Get images \n",
    "    \"\"\"\n",
    "    \n",
    "    session = SessionLocal()    \n",
    "\n",
    "    db_images = session.query(Image).all()[:20]\n",
    "    if not db_images:\n",
    "        logger.warning(\"No images found in the database.\")\n",
    "        return None\n",
    "    \n",
    "    logger.info(f\"Total images retrieved: {len(db_images)}\")\n",
    "\n",
    "    # Filter out images where all masks are zero\n",
    "    filtered_db_images = []\n",
    "    for img in db_images:\n",
    "        masks = session.query(Mask).filter(Mask.image_id == img.id).all()\n",
    "        if masks and not all((np.load(mask.mask_path) == 0).all() for mask in masks):\n",
    "            filtered_db_images.append(img)\n",
    "    \n",
    "    db_images = filtered_db_images\n",
    "    logger.info(f\"Filtered images count: {len(db_images)}\")\n",
    "    \n",
    "    # convert to patches\n",
    "    for img in tqdm(db_images, desc=\"Converting images to patches\"):\n",
    "        save_image_as_patches(img)  \n",
    "\n",
    "    # get patches ids\n",
    "    patches_ids = session.query(Patch).all()\n",
    "    session.close()\n",
    "\n",
    "    if not patches_ids:\n",
    "        logger.warning(\"No patches found in the database.\")\n",
    "        return None\n",
    "\n",
    "    logger.info(f\"Total patches retrieved: {len(patches_ids)}\")\n",
    "\n",
    "    return patches_ids\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_data_from_db()\n",
    "\n",
    "if not dataset:\n",
    "    logger.error(\"No dataset found. Exiting.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb0faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.PatchDataset(dataset)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20285b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TheData = DataLoader(\n",
    "#     training.PatchDataset(dataset[:100]),\n",
    "#     batch_size=20,\n",
    "#     shuffle=True,\n",
    "#     num_workers=0,  \n",
    "#     # pin_memory=True if device.type == \"cuda\" else False\n",
    "# )\n",
    "\n",
    "# Create lists to store metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_dice_scores = []\n",
    "\n",
    "# Split data into train and validation\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Use 80% for training, 20% for validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    training.PatchDataset(train_dataset),\n",
    "    batch_size=32,  # Increased batch size\n",
    "    shuffle=True,\n",
    "    num_workers=4,  # Use multiple workers for data loading\n",
    "    pin_memory=True if torch.cuda.is_available() else False,  # Speed up GPU transfer\n",
    "    prefetch_factor=2  # Prefetch next batches\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    training.PatchDataset(val_dataset),\n",
    "    batch_size=64,  # Can use larger batch size for validation\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# Modified training call with validation\n",
    "model = training.Training(\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    dataloader=train_loader,\n",
    "    val_loader=val_loader,  # Add validation loader\n",
    "    lr=0.0001,\n",
    "    checkpoint_type=\"best\",\n",
    "    model_path=\"data/models\",\n",
    "    num_epochs=50,\n",
    "    early_stopping_patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2cf74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training    \n",
    "# model = training.Training(\n",
    "#     device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "#     dataloader=TheData,\n",
    "#     lr=0.0001,    \n",
    "#     # checkpoint_type=\"best\",\n",
    "#     model_path=\"data/models\",\n",
    "#     # num_epochs=100,\n",
    "#     # early_stopping_patience=20,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_progress(train_losses, val_losses, val_dice_scores):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    ax1.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "    ax1.plot(epochs, val_losses, 'r-', label='Validation Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot Dice scores\n",
    "    ax2.plot(epochs, val_dice_scores, 'g-', label='Validation Dice Score')\n",
    "    ax2.set_title('Validation Dice Score')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Dice Score')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call this after each epoch or at the end of training\n",
    "plot_training_progress(train_losses, val_losses, val_dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd39ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get a batch of test data and run inference\n",
    "model.eval()  # Set to evaluation mode\n",
    "test_batch = next(iter(val_loader))\n",
    "images, masks = test_batch\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(images.to(device))\n",
    "    \n",
    "# Convert tensors to numpy for plotting\n",
    "images = images.cpu().numpy()\n",
    "masks = masks.cpu().numpy()\n",
    "predictions = predictions.cpu().numpy()\n",
    "\n",
    "# if value > .5 then 1 else 0\n",
    "# predictions = (predictions > 0.5).astype(np.uint8)\n",
    "\n",
    "print(f\"Unique values in ground truth masks: {np.unique(masks)}\")\n",
    "print(f\"Unique values in predicted masks: {np.unique(predictions)}\")\n",
    "\n",
    "# Plot results for the first few samples\n",
    "n_samples = min(4, len(images))\n",
    "fig, axes = plt.subplots(n_samples, 5, figsize=(12, 4*n_samples))\n",
    "fig.suptitle('Test Results: Input - Ground Truth - Prediction')\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # Plot original image\n",
    "    axes[i, 0].imshow(images[i].transpose(1, 2, 0))\n",
    "    axes[i, 0].set_title('Input Image')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Plot ground truth mask\n",
    "    axes[i, 1].imshow(masks[i].squeeze()[0], cmap='gray')\n",
    "    axes[i, 1].set_title('Ground Truth channel 1')\n",
    "    axes[i, 1].axis('off')\n",
    "    axes[i, 2].imshow(predictions[i][0], cmap='gray')\n",
    "    axes[i, 2].set_title('Prediction channel 1')\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    axes[i, 3].imshow(masks[i].squeeze()[1], cmap='gray')\n",
    "    axes[i, 3].set_title('Ground Truth channel 2')\n",
    "    axes[i, 3].axis('off')\n",
    "    # Plot predicted mask\n",
    "    axes[i, 4].imshow(predictions[i][1], cmap='gray')\n",
    "    axes[i, 4].set_title('Prediction channel 2')\n",
    "    axes[i, 4].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from app.db.models import Patch\n",
    "from app.db.session import SessionLocal\n",
    "\n",
    "# Create a new session\n",
    "session = SessionLocal()\n",
    "\n",
    "# Query all patches and convert to DataFrame with array paths\n",
    "patches_df = pd.DataFrame([{\n",
    "    'id': patch.id,\n",
    "    'image_id': patch.image_id,\n",
    "    'img_patch': patch.img_patch,  # Keep as array\n",
    "    'mask_patch': patch.mask_patch  # Keep as array\n",
    "} for patch in session.query(Patch).all()])\n",
    "\n",
    "# Close the session\n",
    "session.close()\n",
    "\n",
    "# Display the first few rows and basic information\n",
    "print(\"DataFrame Shape:\", patches_df.shape)\n",
    "print(\"\\nDataFrame Info:\")\n",
    "patches_df.info()\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(patches_df.head())\n",
    "\n",
    "# Save DataFrame to pickle file\n",
    "patches_df.to_pickle(\"data/patches_df.pkl\")\n",
    "print(\"DataFrame saved to data/patches_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b2b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of patches\n",
    "patches_df = pd.read_pickle(\"data/patches_df.pkl\")\n",
    "# to list\n",
    "patches_df = patches_df.to_dict(orient='records')\n",
    "num_patches = patches_df.shape[0]\n",
    "print(f\"Number of patches: {num_patches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378667a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training with improved parameters\n",
    "model, history = training.Training(\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    dataloader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    lr=2e-4,  # Slightly higher learning rate\n",
    "    model_path=\"data/models\",\n",
    "    num_epochs=100,  # More epochs since we have better regularization\n",
    "    early_stopping_patience=15  # More patience with the new scheduler\n",
    ")\n",
    "\n",
    "# Plot the training progress\n",
    "plot_training_progress(\n",
    "    train_losses=history['train_losses'],\n",
    "    val_losses=history['val_losses'],\n",
    "    val_dice_scores=history['val_dice_scores']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
